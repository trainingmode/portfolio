~~~

llm.txt

Author: Alfred R. Duarte
Domain: https://alfred.ad

~~~

![_Hueshift Palette Board, **2023**_](/public/photos/bloomhue/hueshift-board.png "Hueshift Palette Board, Alfred R. Duarte 2023")

> Design & Product

# Hueshift

> **March** - **April 2023**

> _**Note**: For an engineering perspective on this project, please see the [companion article](/portfolio/engineering/under-construction/ "UNDER CONSTRUCTION | Alfred R. Duarte | Portfolio")._

1. [**Purpose**](#purpose)
2. [**Interface Design**](#interface-design)
3. [**User Experience & Testing**](#user-experience-testing)
4. [**Try Hueshift.io üé® üñºÔ∏è**](#try-hueshift.io)

![_254 Spectrum Made with Hueshift, **2025**_](/public/photos/bloomhue/254-hueshift-spectrum.png "254 Spectrum, Hueshift, Alfred R. Duarte 2025")

Often in design, you'll need to take a [color palette](https://en.wikipedia.org/wiki/Color_scheme "Color scheme ‚Äì Wikipedia") and define a [set of light to dark steps](https://en.wikipedia.org/wiki/Color_scheme#Quantitative_schemes "Quantitative schemes ‚Äì Wikipedia") for each color.

![_Warm Palette Extended with Hueshift, **2025**_](/public/photos/bloomhue/palette-to-hueshift-perspective.png "Extended Warm Palette Spectrum, Hueshift, Alfred R. Duarte 2025")

In **interface design**, these values can be used to create _depth_ and _dimension_.

One color with a **lighter** and **darker** step can be overlaid to produce elements with a monochrome, "_single color_" look.

![_Confirmed Label with 131 Hueshift Palette, **2025**_](/public/photos/bloomhue/hueshift-example-confirmed-label.png "Confirmed Label with 131 Hueshift Palette, Alfred R. Duarte 2025")

It helps you **layer related information** in a predictable pattern to how colors **increase & decrease** in **lightness & darkness**.

Just one color can touch a range of situations, with a clear separation of information.

![_Grid of Cards with 29 Hueshift Palette, **2025**_](/public/photos/bloomhue/29-hueshift-palette-overlay.png "Grid of Cards with 29 Hueshift Palette, Alfred R. Duarte 2025")

This predictability can be especially useful when creating **light & dark themes**. It's easier to balance your main _accent_ shade against your _background_ & _foreground_ colors when you have steps that feel natural in distance.

![_Light & Dark Themes with 222 Hueshift Palette, **2025**_](/public/photos/bloomhue/hueshift-example-light-dark-theme.png "Light & Dark Themes with 222 Hueshift Palette, Alfred R. Duarte 2025")

It's also useful when creating subtle shading with a natural feel, while maintaining vibrant readability.

![_Graph ‚Äì Analog Designs UI Styles ‚Ö°, **2023**_](/public/photos/analog-designs/analog-designs-uistyles1-graph.png "Graph ‚Äì Analog Designs UI Styles ‚Ö°, Alfred R. Duarte 2023")

I created **Hueshift** as a tool to automate this process. It uses a [two-stage machine learning process](/portfolio/engineering/under-construction/ "UNDER CONSTRUCTION | Alfred R. Duarte | Portfolio") to help you:

- **Choose interesting colors that complement each other.**
- **Automatically generate a set of light to dark shades for each color.**

**_There are no high-fidelity mockups for this project. Hueshift was designed & built directly in React._**

#### Tools used:

- [VS Code](https://code.visualstudio.com/)
- [React](https://react.dev/)
- [Tailwind CSS](https://tailwindcss.com/)
- [Affinity Designer](https://affinity.serif.com/en-us/designer/) (Figure Diagrams & Example References)
- [Hueshift](https://hueshift.io/) (Color Palettes for Figure Diagrams)

## Purpose

What I found lacking in similar tools are the methods of generating **harmonious colors**.

Most tools are limited to either [mathematical methods](https://en.wikipedia.org/wiki/Color_scheme#Harmonious_schemes "Harmonious schemes ‚Äì Color scheme ‚Äì Wikipedia"), or _manual selection_.

I wanted to create a tool that bridged the gap between mathematical precision and the organic artistry of human-selection.

**Hueshift** recursively generates harmonious colors starting from the **base hue**.

This method allows for a wider range of generated palettes, with colors that still feel naturally harmonious.

## Interface Design

**Hueshift** takes on an interface that is purposefully _form_ over _function_.

In a world where UI is reduced to a single chat box, I wanted to take a different approach.

I wanted to imagine an interface that is as **engaging & artistically inspiring** as it is **functional to use**.

### Inspiration

Inspiration for the **palette board** came from those wall of swatches inside real-world paint stores.

![_Wall of Swatches, **GPT-4o 2025**_](/public/photos/misc/swatch-board.png "an image of a wall of swatches at a paint store, iphone shot")

The **palette board** attempts to capture the dynamic nature of a real-world swatch wall in a paint store.

![_Hueshift Compact Palette Board Close-up, **2023**_](/public/photos/bloomhue/hueshift-board-compact-closeup.png "Hueshift Compact Palette Board Close-up, Alfred R. Duarte 2023")

### Features

**Hueshift** is highly interactive.

You can click to copy any **shade** as a **hex code**.

You can **drag & drop** rows of swatches to reorder them or toss them out.

![_Swatch Drag & Drop on Hueshift Palette Board, **2023**_](/public/photos/bloomhue/hueshift-board-drag-drop-swatch.png "Swatch Drag & Drop on Hueshift Palette Board, Alfred R. Duarte 2023")

Using the **sliders**, you can adjust the **hue** of the **base color**. You can also adjust palette-wide **lightness & saturation**.

You can generate up to **`8` harmonious color swatches** in a single palette.

![_Hueshift Sliders, **2023**_](/public/photos/bloomhue/hueshift-sliders.png "Hueshift Sliders, Alfred R. Duarte 2023")

Enable **Greytone** to generate a **greyscale** palette.

![_Hueshift Greytone Palette, **2025**_](/public/photos/bloomhue/hueshift-greytone-palette.png "Hueshift Greytone Palette, Alfred R. Duarte 2025")

You can copy rows of swatches as **JSON**, or copy the entire palette as **JSON**.

Click the **`Palettes ‚¨áÔ∏è`** button to download a `palette.json` file of all your starred palettes.

```json
{
  "50": "#f2fdfc",
  "100": "#cbfbf6",
  "200": "#98f6ef",
  "300": "#5deae6",
  "400": "#2bd4d2",
  "500": "#14b6b8",
  "600": "#0d9196",
  "700": "#0f7175",
  "800": "#115a5f",
  "900": "#134b4e",
  "950": "#042a2f",
  "hue": 180
}
```

With **Hueshift Pro**, you can edit the colors used to influence the **model** that generates _harmonious colors_.

![_Hueshift Model Selector, **2023**_](/public/photos/bloomhue/hueshift-models.png "Hueshift Model Selector, Alfred R. Duarte 2023")

If you feel like shades generated are "missing something", you can add or remove colors to influence the **model** to generate entirely new shades and palettes.

**Hueshift** ships with **_`98`_** pre-defined **color models**, with `21` **color models** enabled by default.

It also ships with **_`19`_** **greytone models**, with `5` **greytone models** enabled by default.

## User Experience & Testing

I conducted light **user testing** with some designer & marketing friends to see how they used **Hueshift** and their thoughts on the process provided by the tool.

![_Hueshift Palette Board Close-up, **2023**_](/public/photos/bloomhue/hueshift-board-closeup.png "Hueshift Palette Board Close-up, Alfred R. Duarte 2023")

### Testing Process

Feedback was collected through various forms, mainly **text messaging** and **Discord**. With a small test group, I wanted to meet people where they were.

I sent around a survey as text that people could easily reply to rather than ask them to fill out a form. I provided an open space for suggestions & comments.

I sent them a succinct set of targeted questions to understand their usage patterns:

1. **Did you produce any palettes that you used, or would use in a project?**
2. **Was there any point you said, "_I hope/wonder if Hueshift could do this?_" What were trying to do?**
3. **What did you find cumbersome about the process or interface?**
4. **What reasons hold you back from using Hueshift in your workflow?**

### Feedback Summary

> _"...really fun to play with!"_

Through this research, the feature for **dragging a row of swatches out of the palette to remove it** surfaced. Many people didn't understand how to get rid of swatches that they didn't want, and just wanted to "toss them out".

I also received feedback from basically everyone for one feature:

> _"Can I generate a palette from an image?"_

While this was out of the project scope, it's a great suggestion for a future release.

### Conclusions

In all, most found the process mostly intuitive and easy to navigate. However, no designers really mentioned they'll actually use the tool. The honest feedback I received was picking colors manually in-app was just quicker and easier than using a totally separate tool.

With that said, my marketing friends were very excited about its potential, but it was still just a bit too hands-on for them.

I would like to revisit this project and incorporate the feedback I received. I think making the process even more streamlined would help increase the tool's usability and get people to actually adopt it.

## Try Hueshift.io üé® üñºÔ∏è

Embedded below ‚¨áÔ∏è or at [beta.hueshift.io](https://beta.hueshift.io "Hueshift.io") (_best viewed in a separate tab_).

#### Tips:

- Click the <span class="inline-block text-blue-500"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="size-4"> > <path stroke-linecap="round" stroke-linejoin="round" d="M9.879 7.519c1.171-1.025 3.071-1.025 4.242 0 1.172 1.025 1.172 2.687 0 3.712-.203.179-.43.326-.67.442-.745.361-1.45.999-1.45 1.827v.75M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9 5.25h.008v.008H12v-.008Z" /> > </svg></span> **`Help`** button to open the **Help Guide**.

- Switch your system color scheme to see **light** and **dark** modes.

- Click **`Upgrade to Pro`** to unlock the **Full Version** of the app (it's free).

@[115%](https://beta.hueshift.io/)

---

### [üìö **Book a meeting to discuss your project. [‚ûî](mailto:alfred.r.duarte@gmail.com)**]{.highlight}

[**alfred.r.duarte@gmail.com**](mailto:alfred.r.duarte@gmail.com "Gmail ‚Äì Alfred R. Duarte")

.

~~~

The above material is owned by the author.

This file was generated with SASHA.

~~~
~~~

llm.txt

Author: Alfred R. Duarte
Domain: https://alfred.ad

~~~

![_iOS 6-style Emoji Grid, **2022**_](/public/photos/spaceboy3000/ios6-emoji-grid.png "Emoji Grid, Alfred R. Duarte 2022")

> Case Study ‚Äî Design

# Color Emoji (iOS 6.0)

> **June 2022**

1. [**Secrets of Emoji Design**](#secrets-of-emoji-design)
2. [**Anatomy of Emoji**](#anatomy-of-emoji)
3. [**Dissection & Outlines**](#dissection-outlines)
4. [**Comparisons & Close-ups**](#comparisons-close-ups)
5. [**Side-by-Side Comparison**](#side-by-side-comparison)

I've always loved **Apple**'s [icon design](https://developer.apple.com/design/human-interface-guidelines/icons "Apple Human Interface Guidelines: Icons"). Their depth and precision is truly inspiring.

The set of original **iOS 6.0** emoji are timeless & iconic. Their style set the standard for emoji design.

I wanted to take a look and see how the original emoji were made. If you try to blow emoji up to a large size, you'll find they're just images. The [original designers have shared](https://blog.emojipedia.org/who-created-the-original-apple-emoji-set/ "Who Created The Original Apple Emoji Set? ‚Äì Emojipedia") that they were digital paintings, but I wanted to see what I could do using vector alone.

Recently, I had just completed a similar [case study on pushing the limits of vector shapes & gradients for UI design](/portfolio/design/render-optimized-skeumorphic-ui-2022/ "Case Study: Render‚ÄìOptimized Skeumorphic UI, 2022 | Alfred R. Duarte | Portfolio"). That project equipped me with very delicate _shading_ & _composition_ techniques using only vector. I wanted to see how those same techniques could apply to the depth & detail of emoji design.

**_All of the emoji I created in this project are purely vector-based._**

> _**Disclaimer**: I am **not affiliated** with Apple. Emoji referenced in comparisons are **unmodified** and used for educational purposes only. Close-ups & breakdowns are all my own work._

#### Assets produced:

**`56`** **Expressions**

- **`5`** **Heads**
- **`33`** **Eyes**
- **`18`** **Eyebrows**
- **`29`** **Mouths**
  - **`3`** **Teeth**
  - **`3`** **Tongues**
  - **`2`** **Cheek Blushes**
  - **`1`** **Chin**
- **`12`** **Accessories**

**`21`** **Bonus**

- **`4`** **People**
- **`1`** **Heart**
- **`16`** **Symbols**

#### Tools used:

- [Affinity Designer](https://affinity.serif.com/en-us/designer/)

## Secrets of Emoji Design

![_[Sun](https://emojipedia.org/apple/ios-6.0/sun "Sun on Apple iOS 6.0 ‚Äì Emojipedia") & [Surprised](https://emojipedia.org/apple/ios-6.0/face-with-open-mouth "Surprised Face with Open Mouth on Apple iOS 6.0 ‚Äì Emojipedia") Emoji Overlap, **Apple Color Emoji (iOS 6.0) 2012**_](/public/photos/spaceboy3000/emoji-overlap-sun-surprised.png "Sun & Surprised Emoji Overlap, Apple 2012")

_Which came first_‚Äìthe **_sun_** or the **_surprised face_**?

I was browsing the original emoji set looking for strong reference candidates. I noticed the shading for the body of the **sun** emoji was nearly identical to the body of the **emoji face**/**head**.

Rather than attempt an emotive emoji, I decided to use the **sun** emoji as my starting reference for breaking down the anatomy of the **emoji face**.

While I can't unmask specifics around my techniques, I can share about the principles I used and my process behind breaking down **Apple**'s emoji design.

### Light & Scene

Apple designers carry a strong understanding of _physical-based_ **light** & **scene composition**.

![](/public/photos/spaceboy3000/emoji-scene-composition.png "Emoji Scene Composition Diagram, Alfred R. Duarte 2025")

Emoji take on _studio-quality lighting_, likely from a **3-point lighting setup** (not pictured).

A strong **light source** seems to be positioned vertically above the emoji, casting a strong _highlight_ on subjects. **Fill** & **back lighting** are used to create a sense of depth, reducing contrasting shadows while maintaining vibrancy.

#### **_A Word on the Physical Properties of Light_**

The **light spectrum** is a range of _wavelengths_.

These are broken into `3` categories:

- **Infrared** wavelengths, low energy, longer than red;
- **Visible** wavelengths, medium energy, between red and blue;
- **Ultraviolet** wavelengths, high energy, shorter than blue.

Notice the colors: **red** & **blue**.

When you shift colors, imagine the wavelengths of light.

You're shifting more üî¥ **red**, or more üîµ **blue**.

üî¥ **Red** is lower energy and _darker_. üîµ **Blue** is higher energy and _brighter_.

### Object Composition

As previously mentioned, emoji were originally digital paintings. Objects don't really follow [shape-building principles](https://helpx.adobe.com/illustrator/using/building-new-shapes-using-shape.html#shape-builder "Build new shapes with Shaper and Shape Builder tools ‚Äì Adobe Illustrator Help") like we're used to seeing from **Apple**'s iconography.

With that said, their emoji are still highly compositional, with mostly-geometric shapes used to build objects.

![_Sun Emoji Vector & Outlines Dissection, **2025**_](/public/photos/spaceboy3000/emoji-dissection-sun.png "Sun Emoji Dissection, Alfred R. Duarte 2025")

**Apple** designers likely **painted onto flat shapes** to create depth and simulate light. They likely used a combination of **layer effects** as well as the trusty **brush tool** to create the final look.

My own technique reuses shape layers with gradients to construct depth out of as few vertices as possible. This to offload processing required by the **CPU** and relying on shaders to push intensive rendering work on the **GPU**.

### Edges, Faces, & Bodies

In typical **Apple** style, much focus is placed on **edge definition**. **Edges** capture _shape_ & _form_ to create their signature sense of depth.

**Edges** & **faces** catch light to build _definition_.

**Faces** mold form and express _physicality_. These are material-based properties, like _specular_, _diffuse_, _ambient_; to portray things like _roughness_, _glossyness_, etc.

**Bodies** cast shadow and fill light-space for a sense of _volume_.

![_Sun Emoji Close-up, **2022**_](/public/photos/spaceboy3000/emoji-closeup-sun.png "Sun Emoji Close-up, Alfred R. Duarte 2022")

### Blending & Gradients

The key to achieving the classic **Apple** emoji look is **blending**.

Understanding how [physical light sources interact](#a-word-on-the-physical-properties-of-light) with materials and with one another is key.

![_Fire Emoji Close-up, **2022**_](/public/photos/spaceboy3000/emoji-closeup-fire.png "Fire Emoji Close-up, Alfred R. Duarte 2022")

**Strong composition** lays the foundation for vibrant _blending_ work.

The classic approach of using a **base**, with **layers of shading** to create _depth_ is how you produce strong results.

Take extra care of how you shape **edges** and **faces** against the scene lighting.

![_Fire Emoji Base Gradient & Shading Dissection, **2025**_](/public/photos/spaceboy3000/emoji-dissection-fire.png "Fire Emoji Base Gradient & Shading Dissection, Alfred R. Duarte 2025")

## Anatomy of Emoji

Emoji rely heavily on strong principles of **light** & **blending**.

**Lines** take _shape_ and mold _form_ into the face base. **Gradients** capture depth from the light cast on the face surface.

Emoji can be broken into two main parts: **face** & **expression**.

### Emoji Face Anatomy

The **face** is the foundation for all emotive emoji.

![](/public/photos/spaceboy3000/emoji-face-anatomy.png "Emoji Face Anatomy Diagram, Alfred R. Duarte 2025")

The emoji **face** is split into `5` layers:

1. **Highlight**
2. **Flush**
3. **Border**
4. **Base**
5. **Shadow**

This anatomy is identical for all emotive emoji. This includes the [üò° **Enraged Face**](https://emojipedia.org/apple/ios-6.0/pouting-face "Enraged Face on Apple iOS 6.0 ‚Äì Emojipedia") emoji, which takes on a full-face **flush**. The **base** & **border** are only recolored for the two [üòà **Smiling Face with Horns**](https://emojipedia.org/apple/ios-6.0/smiling-face-with-horns "Smiling Face with Horns on Apple iOS 6.0 ‚Äì Emojipedia") & [üëø **Angry Face with Horns**](https://emojipedia.org/apple/ios-6.0/angry-face-with-horns "Angry Face with Horns on Apple iOS 6.0 ‚Äì Emojipedia") devil emoji.

For the original set, the only time the **face** changes form is for the [üò± **Face Screaming in Fear**](https://emojipedia.org/apple/ios-6.0/face-screaming-in-fear "Face Screaming in Fear on Apple iOS 6.0 ‚Äì Emojipedia") emoji. It takes the shape of the [üëΩ **Alien**](https://emojipedia.org/apple/ios-6.0/alien "Alien on Apple iOS 6.0 ‚Äì Emojipedia") emoji, however, its anatomy remains the same.

### Emoji Expression Anatomy

**Expressions** are built on top of the **face** anatomy.

![](/public/photos/spaceboy3000/emoji-anatomy.png "Emoji Expression Anatomy Diagram, Alfred R. Duarte 2025")

An emoji **expression** consists of `5` layers:

1. **Accessories**
2. **Eyebrows**
3. **Eyes**
4. **Mouth**
5. **Face**

**Expressions** reuse a set of _anatomy_, and combine other emoji _anatomy_ to create unique **expressions**. Many _eyebrows_, _eyes_, & _mouths_ are shared across multiple emoji.

![_Selection of Emoji with Reused Anatomy, **2022**_](/public/photos/spaceboy3000/emoji-closeup-reused-anatomy.png "Selection of Emoji with Reused Anatomy, Alfred R. Duarte 2022")

## Dissection & Outlines

My technique for creating these emoji is purely **vector-based**.

Everything is built out of **shape layers** with **gradients**. There are **_no_** _layer effects_ or _masks_ used in this project.

![_Smiling Face Emoji Vector+Outlines & Outlines Dissection, **2025**_](/public/photos/spaceboy3000/emoji-dissection-smiling.png "Smiling Face Emoji Dissection, Alfred R. Duarte 2025")

I didn't use any brush-tricks or vectorization tools. Everything was either built from **geometric shapes** or by using the **pen tool**.

![_Hundred Points Emoji Outlines, **2025**_](/public/photos/spaceboy3000/emoji-outlines-hundred.png "Hundred Points Emoji Outlines, Alfred R. Duarte 2025")

There may be inconsistencies in the vertex placements on the outlines above due to the technique used to render the vertices. I split the line into individual paths, then used `open square` **line-ends** to create the vertices.

## Comparisons & Close-ups

Below are some close-up comparisons of my emoji with **Apple**'s iOS 6.0 emoji.

A small reminder that my emoji are **vector-based** and **Apple**'s are **pixel-based**.

![](/public/photos/spaceboy3000/emoji-comparison-alien.png "Alien Emoji Comparison; Apple 2012, Alfred R. Duarte 2022")

![](/public/photos/spaceboy3000/emoji-comparison-crying.png "Crying Emoji Comparison; Apple 2012, Alfred R. Duarte 2022")

![](/public/photos/spaceboy3000/emoji-comparison-angry.png "Enraged Emoji Comparison; Apple 2012, Alfred R. Duarte 2022")

![](/public/photos/spaceboy3000/emoji-comparison-finger.png "Index Pointing Up Emoji Comparison; Apple 2012, Alfred R. Duarte 2022")

![](/public/photos/spaceboy3000/emoji-comparison-party.png "Party Popper Emoji Comparison; Apple 2012, Alfred R. Duarte 2022")

![_Ghost Emoji Close-up, **2022**_](/public/photos/spaceboy3000/emoji-closeup-ghost.png "Ghost Emoji Close-up, Alfred R. Duarte 2022")

![_Bomb Emoji Close-up, **2022**_](/public/photos/spaceboy3000/emoji-closeup-bomb.png "Bomb Emoji Close-up, Alfred R. Duarte 2022")

![_Smiling Face with Sunglasses Emoji Close-up, **2022**_](/public/photos/spaceboy3000/emoji-closeup-sunglasses.png "Smiling Face with Sunglasses Emoji Close-up, Alfred R. Duarte 2022")

## Side-by-Side Comparison

%[iOS 6.0 Emoji Grid, Apple 2012](/public/photos/spaceboy3000/ios6-emoji-grid-apple.png)
%[iOS 6.0 Emoji Grid, Alfred 2022](/public/photos/spaceboy3000/ios6-emoji-grid-alfred.png)

> Use the slider above to compare my emoji (_left_) against the original **Apple iOS 6.0** emoji (_right_).

For only using _vector shapes_ & _gradients_‚ÄìI think I got pretty close!

Looking back at them now, I see a few small things besides shading differences:

- The teeth should take on a shadow from the top lip;
- The devils' eyebrows & eyes should be touching;
- And the flushed-blue faces should have dark-blue eyebrows.

_Soo_ close! üòÑ

The sizes of the original **Apple** üò© & üò´ emoji are slightly larger than all others for some reason‚Äìlikely to accommodate their larger mouths. I left mine intentionally all an identical size.

In all, this was a fun project! My goal wasn't to perfectly recreate the original emoji, just to see how far pure-vector could go. In the end, I learned a lot from **Apple**'s emoji design and got to see how far I could push my vector & gradient skills. üñºÔ∏è

## Resources

- [**Apple Color Emoji (iOS 6.0)**, _Emojipedia_](https://emojipedia.org/apple/ios-6.0 "Apple Color Emoji (iOS 6.0) ‚Äì Emojipedia")

##### Apple Color Emoji (iOS 6.0) Referenced

- [‚òÄÔ∏è **Sun**, _Emojipedia_](https://emojipedia.org/apple/ios-6.0/sun "Sun on Apple iOS 6.0 ‚Äì Emojipedia")
- [üòÆ **Face with Open Mouth**, _Emojipedia_](https://emojipedia.org/apple/ios-6.0/face-with-open-mouth "Face with Open Mouth on Apple iOS 6.0 ‚Äì Emojipedia")
- [üëΩ **Alien**, _Emojipedia_](https://emojipedia.org/apple/ios-6.0/alien "Alien on Apple iOS 6.0 ‚Äì Emojipedia")
- [üò≠ **Loudly Crying Face**, _Emojipedia_](https://emojipedia.org/apple/ios-6.0/loudly-crying-face "Loudly Crying Face on Apple iOS 6.0 ‚Äì Emojipedia")
- [üò° **Enraged Face**, _Emojipedia_](https://emojipedia.org/apple/ios-6.0/pouting-face "Pouting Face on Apple iOS 6.0 ‚Äì Emojipedia")
- [‚òùÔ∏è **Index Pointing Up**, _Emojipedia_](https://emojipedia.org/apple/ios-6.0/index-pointing-up "Index Pointing Up on Apple iOS 6.0 ‚Äì Emojipedia")
- [üéâ **Party Popper**, _Emojipedia_](https://emojipedia.org/apple/ios-6.0/party-popper "Party Popper on Apple iOS 6.0 ‚Äì Emojipedia")

---

### [üìö **Book a meeting to view the .afdesign files. [‚ûî](mailto:alfred.r.duarte@gmail.com)**]{.highlight}

[**alfred.r.duarte@gmail.com**](mailto:alfred.r.duarte@gmail.com "Gmail ‚Äì Alfred R. Duarte")

~~~

The above material is owned by the author.

This file was generated with SASHA.

~~~
~~~

llm.txt

Author: Alfred R. Duarte
Domain: https://alfred.ad

~~~

![_Sample UIs 1-7 on Desktop ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui-1-7-desktop.png "Sample UIs 1-7 on Desktop ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

> Case Study ‚Äî Design

# Render‚ÄìOptimized Skeumorphic UI

> **October** - **December 2022**

1. **[Purpose](#purpose)**
2. **[Process](#process)**
3. **[Fantasy Plugins](#fantasy-plugins)**
4. **[Symbols](#symbols)**

![_UI 1 ‚Äì Analog Designs UI Styles ‚Ö†, **2022**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui1-preview.png "UI 1 ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022")

_**All of the interface assets I created in this project are purely vector-based**, excluding some image-based textures._

#### üéöÔ∏è Assets produced:

**`282`** **Assets**

- **`30`** **Panels**
- **`38`** **Knobs**
- **`14`** **Sliders**
- **`26`** **Buttons**
- **`58`** **Accessories**
- **`11`** **Textures**
- **`5`** **Fonts**

**`225`** **Symbols**

#### Tools used:

- [Affinity Designer](https://affinity.serif.com/en-us/designer/)

## Purpose

A **music plugin** is an interface users interact with to control parameters of an **audio processing pipeline**.

Important to note, the interface is just a skin. The _audio processor_ is the main consumer of resources. This means interfaces need to be lightweight and mindful of performance overhead.

_Audio processing_ happens in realtime on the **CPU**. Plugin UIs need to offload as much rendering as possible to the **GPU**. In practice, this means reducing the amount of **draw calls** & **vertex buffers** (typically w/ _subranging_ & _instancing_) processed by the **CPU**.

For example, reallocating one (large) **VBO** vs. updating separate **VBOs** for each plugin window instance can free up **CPU**. Rather than your **CPU** processing each instance (`O(n)`), it can process a single **VBO** for all instances and upload it to the **GPU** (`O(1)`). Optimizations like this are crucial when you rely on individual-frame performance optimizations.

Each frame of processing (both _audio_ & _UI_) needs to happen in as little time as possible. Otherwise, you risk glitching & artifacts in your audio output.

That's what the **buffer size** on your **audio interface** is for‚Äìadjusting the amount of audio samples processed per frame. A larger buffer size means more samples are processed, but at the expense of latency (the audio playing back later than it appears on the screen).

A **music plugin host** dispatches each chunk of samples at a consistent interval (the **buffer size**). If a frame stalls or exceeds its buffer period, the following frame will not start in time and underrun the buffer.

```
‚ï≠< Frame 1 >  ‚ï≠< Frame 2 >  ‚ï≠< Frame 3 >
‚îú ‚úì 10ms      ‚îú ‚®Ø 20ms      ‚îú ‚úì 10ms
‚îÇ Pass        ‚îÇ Underrun ‚Üí  ‚îÇ Artifacts
```

### Rendering Options

For rendering music tooling interfaces in software, you have a few options:

1. **Image textures (e.g. PNG)**
2. **Vector-based renderer**
3. **3D-based renderer**, (_can include shading pipelines_)

**Image textures** are the most common, being the easiest and least resource intensive. You get detailed designs without the overhead.

They have their obvious limitations. Fixed sizing is a major issue for distribution across the wide array of desktop screen sizes & resolutions. (_Looking at you, ultrawide screen users._)

To scale the window for an **image texture**-based UI, you need to include different sizes of all your images for each target window scale. Otherwise, elements of your UI will look pixelated/blurry when scaled up.

Another slowdown is the workflow for rendering animation sequences. You have to render _each frame_ as an image, then assemble it as an **animation strip**. There are [many](https://navelpluisje.github.io/figma-knob-creator "Figma Knob Creator | A Figma plugin for creating knob stacks") [tools](https://tripletechaudio.com/products/knob-maker-for-vst/ "Knob Maker - TripleTech") that can help automate this process. I need to mention the web version of the classic [KnobMan by g200kg](https://www.g200kg.com/en/webknobman/index.html?f=3p_wedge.knob&n=2 "WebKnobMan Knob Designer | g200kg Music & Software") that has been used to render knobs & sliders for countless music plugin UIs throughout the decades.

![_Knob 22 Animation Sequence ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-knob22-sequence.png "Knob 22 Animation Sequence ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

**Vector-based renderers** solve the sizing issue, but can incur significant performance overhead with the number of moving/animated parts in a music plugin UI.

Lots of vector-based plugins simplify graphical complexity to make up for the increase in overhead, and craft unique stylized looks.

![_[FabFilter Pro-Q 4](https://www.fabfilter.com/products/pro-q-4-equalizer-plug-in "FabFilter Pro-Q 4 - Equalizer Plug-In") Plugin UI Screenshot, **FabFilter 2025**_](/public/photos/misc/fabfilter-pro-q-4.jpg "FabFilter Pro-Q 4 Plugin UI Screenshot, FabFilter 2025")

The cost of **3D-based renderers** both to develop & create assets for, plus the overhead of rendering in realtime, means most music plugins don't use them.

Instead, plugins with 3D-based elements just render static images and animate the image sequences. Some plugins blend rendered elements with vector-based interactive elements. This way, continuous animation is smooth without most of the overhead cost.

![_[Arturia Jup-8 V](https://www.arturia.com/products/software-instruments/jup-8-v/overview "Arturia - Jup-8 V") Plugin UI Screenshot, **Arturia 2025**_](/public/photos/misc/arturia-jup-8-v.png "Arturia Jup-8 V Plugin UI Screenshot, Arturia 2025")

### Project Goals

The goal of this project was to develop a set of **vector-based techniques for rendering skeumorphic music plugin UIs**.

The idea is that the UI would be drawn:

- **Once (`1`) when the plugin window is first opened/drawn**
- **When the user resizes the plugin window**, (_continuous_ or _throttled_/_debounced_)

This ensures the UI can be truly responsive‚Äìand always drawn perfectly to scale‚Äìwhile reducing overhead.

![_Sample UI 1 Close-up ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui1-closeup.png "UI 1 Close-up ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

_Localized areas_ are then redrawn as needed for:

- **Parameter changes** (e.g. user adjusts a knob)
- **State changes** (e.g. user hovers over a button)
- **Animation** (e.g. spectrum analyzer graph)

Animation for controls like knobs & sliders can be **fully continuous** and still stay lightweight.

This eliminates the need for prerendered animation assets, constructing animation strips, and prerendering multiple sizes of the same asset for each target window scale.

**Flat-shading** is the final component to reducing **draw calls** & **vertex buffers** processed by the **CPU**. No _lighting_ (faster frag shaders), no _normals_ (even faster), no _specular_; _zero physically-based rendering_. Just flat colors & gradients. Even shadows are flat gradients.

## Process

I collected a set of **`57` music interface references**, ranging from vintage hardware to modern software.

I analyzed common controls, the styles used to convey functionality, and user experience patterns between interfaces. 'Lotta knobs.

![_Reference Interfaces, **Google Images 2022**_](/public/photos/analog-designs/analog-designs-ui-styles-i-references.png "Reference Interfaces, Google Images 2022")

Each control follows a predictable layer architecture. For each control type‚Äìknobs, sliders, & buttons‚ÄìI constructuced reusable architecture for building new controls.

Below is an example of **`Knob 22`** and its structure.

![_Knob 22 Anatomy ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-knob-anatomy.png "Knob Anatomy ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

The two bottom layers, **Ring Notches** & **Base Border**, are static.

The two top layers, **Top Face** & **Indicator**, can be animated depending on the design of the control.

Certain designs may only need to animate the **Indicator** **CPU**-side, animating gradients **GPU**-side.

A key aspect to these techniques is **minimizing the amount of vector data** processed by the **CPU**.

The lower the amount of animated vertices, the lower the **CPU** processing. The lower the amount of vertices alltogether, the greater the amount of window instances that can be drawn together.

![_Knob 22 Vector & Outlines Dissection ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-knob22-dissection.png "Knob 22 Dissection ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

Vertex counts can rise slightly, as long as the high-vertex element either remains static (only drawn on window context change) or can be offloaded & animated **GPU**-side.

Remember our knob animation from earlier in the article. Rather than continuous animation, costing calculations for each frame of rotation animation, a _lookup table_ can be used to store values used in the animation.

Controls with discrete/stepped values can take this a step further and reduce the number of intervals stored in the LUT.

![_Knob 22 Animation Sequence Breakdown ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-knob22-sequence-breakdown.png "Knob 22 Animation Sequence Breakdown ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

In fact, you can just precompute curve values into a LUT and reuse for drawing each unchanged frame of animation.

Design choices can close the loop and further reduce processing involved. You don't need your **CPU** to calculate vertices of a perfect circle when your **GPU** can do it. A perfect circle doesn't need a LUT for rotation values.

The combination of these techniques can reduce **CPU** load for skeuomorphic-style interfaces, while still allowing for high-quality, responsive, & scalable interfaces.

![_Sample UI 1 Vector & Outlines Dissection ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui1-dissection.png "UI 1 Dissection ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

## Fantasy Plugins

Below are a handful of fantasy music plugin UIs I threw together in a few hours.

None of the interfaces below were orignally designed as a cohesive unit‚Äìthey were all assembled using separate assets from this set.

All of the interfaces below are fully vector-based.

![_Sample UI 1 ‚Äì Analog Designs UI Styles ‚Ö†, **2022**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui1.png "Sample UI 1 ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022")

![_Sample UI 2 ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui2.png "Sample UI 2 ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

![_Sample UI 3 ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui3.png "Sample UI 3 ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

![_Sample UI 4 ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui4.png "Sample UI 4 ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

![_Sample UI 5 ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui5.png "Sample UI 5 ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

![_Sample UI 6 ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui6.png "Sample UI 6 ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

The legality surrounding the exclusion of woodgrain textures from a set of music plugin UIs is a bit of a gray area. I've included a sample with woodgrain below to ensure compliance.

![_Sample UI 7‚Ä† ‚Äì Analog Designs UI Styles ‚Ö†, **2022 & 2025**_](/public/photos/analog-designs/analog-designs-ui-styles-i-ui7.png "Sample UI 7 ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022 & 2025")

‚Ä† _Sample UI 7 contains an image texture for the woodgrain side panels._

## Symbols

Included with the set are `225` **line icon symbols**.

I wanted to experiment with an idea I had for constructing the **grid** & **guide system**.

![_Flag Symbol with Guides ‚Äì Analog Designs UI Styles ‚Ö†, **2022**_](/public/photos/analog-designs/analog-designs-ui-styles-i-symbol-guides.png "Flag Symbol with Guides ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022")

I used concepts from [shape building](https://helpx.adobe.com/illustrator/using/building-new-shapes-using-shape.html#shape-builder "Build new shapes with Shaper and Shape Builder tools ‚Äì Adobe Illustrator Help") to **anticipate curves & placements into a set of guides**.

![_Symbol Samples ‚Äì Analog Designs UI Styles ‚Ö†, **2022**_](/public/photos/analog-designs/analog-designs-ui-styles-i-symbols.png "Symbol Samples ‚Äì Analog Designs UI Styles ‚Ö†, Alfred R. Duarte 2022")

My conclusions of the **guides** were mixed.

The **guides** did help speed up creation by helping me quickly place curves. But I also found them a bit restrictive for some compositions. I'll likely stick with something more traditional for most projects.

---

### [üéõÔ∏è **Book a meeting to discuss your project. [‚ûî](mailto:alfred.r.duarte@gmail.com)**]{.highlight}

[**alfred.r.duarte@gmail.com**](mailto:alfred.r.duarte@gmail.com "Gmail ‚Äì Alfred R. Duarte")

.

~~~

The above material is owned by the author.

This file was generated with SASHA.

~~~
~~~

llm.txt

Author: Alfred R. Duarte
Domain: https://alfred.ad

~~~

![_The Centaurs AI Summit, **Davos 2025**_](/public/photos/stromback/ai-summit-panel-2025.jpg "The Centaurs AI Summit, World Economic Forum 2025")

> Design

# The Centaurs AI Summit, World Economic Forum 2025

> **December 2024**

1. [**Motif**](#motif)
2. [**Slides**](#slides)
3. [**Branding**](#branding)
4. [**Graphics**](#graphics)

[Ollivier Oullier](https://www.weforum.org/people/olivier-oullier/ "Ollivier Oullier | World Economic Forum"), PHD (founder/CEO of [Inclusive Brains](https://www.allianz-trade.com/en_global/news-insights/news/prometheus.html "Allianz Trade x Inclusive Brains")) is a neuroscientist, AI entrepreneur and investor. He was hosting a multi-speaker summit through his organization, [The Centaurs](https://thecentaurs.ai/ "The Centaurs AI SUMMIT ‚Äì Davos 2025 Edition"), on day 1 of the [World Economic Forum in Davos](https://www.weforum.org/ "The World Economic Forum"). Their new podcast, [The Centaurs AI Podcast](https://www.instagram.com/thecentaursai/ "The Centaurs AI Summit & Podcast Instagram"), launched during the summit.

I provided the **pitch deck** & **event schedules**. These materials were sent to attendees prior to the event and were used during the summit.

I was contracted to provide:

- **Initial concepts**
- **Branding**
- **Decks/presentation slides**
- **Scheduling posters/flyers**
- **Lay the groundwork & systems for asset creation**
- **Render high-quality graphics for display** (_shown on **CNBC** coverage_)

> _This project can be seen as an extension of my work with [Stromback Venues](/portfolio/design/stromback-venues-davos-25-2024/ "Stromback Venues (Davos '25), 2024 | Alfred R. Duarte | Portfolio")._

For this project, the clients wanted a _hyper-modern_, _forward-thinking_ aesthetic. _Luxury = refinement_.

**Simplicity** & **bold contrast** were heavily employed to offer stark and captivating visuals for viewers, with a sense of _futuristic mystique_.

I continued my goal from past deck commissions: **tell visual stories while maximizing readability**.

Completed materials were sent to a team in Portugal for further asset creation; ranging from videos, social content, & a website.

#### Project length:

**`2 weeks`**

#### Materials produced:

- **`1`** **deck**; _Figma_
- **`1`** **deck**; _Google Slides_
- **`9`** **slides**; _Figma_
- **`9`** **slides**; _Google Slides_
- **`17`** **high-quality display graphics**; _Figma_

#### Tools used:

- [Figma](https://www.figma.com/)
- [Google Slides](https://workspace.google.com/products/slides/)
- [Google Drive](https://workspace.google.com/products/drive/) (Team Collaboration)

## Motif

We've all been there: you design a strong motif with simple-enough patterns, send off guidelines & mockups to your client's team, and they return with... well, something else entirely.

This project was incredibly fast-paced, involved multiple stakeholders' input, was under a tight deadline‚Äìand the client's team was based in Portugal while I was based in Los Angeles.

I wanted to create a motif that could _truly_ be **easily adapted to different contexts**, ensuring cohesion under these extreme constraints.

![_The Centaurs AI Summit Motif & Breakdown, **2024** & **2025**_](/public/photos/stromback/ai-summit-motif-2025.png "The Centaurs AI Summit Motif, Alfred R. Duarte, 2024 & 2025")

An adventurous, bold look was chosen to capture the new frontiers provided by emerging AI technologies.

Focus was placed on capturing a striking elegance, rather than an over-the-top presence.

A **black base**, with **periwinkle accents** & **deep-violet undertones** evoked a sense of _adventure_ & _mystery_.

This motif was carried through the deck and all other assets produced for this project.

## Slides

I produced the **main event deck** & **scheduling** given to attendees.

- Custom **deck slides** were designed in _Figma_.
- Slide content was produced based on an outline document (bullet-points) provided by the clients.
- Upon approval, the _Figma_ designs were then **fully recreated in Google Slides** for presentation & sharing.
- **Scheduling was produced** based on a similar outline document provided by clients.
- **Slides were prepared** in _Figma_ and sent to the team in Portugal for further asset creation.

## Branding

![_The Centaurs AI Logo Icon, **2024**_](/public/photos/stromback/centaur-ai.png "The Centaurs AI Logo Icon, Alfred R. Duarte 2024")

- Branding elements, including a **logo icon** & **wordmark**, were produced for the event & podcast.
- Drawing on the clients' existing assets and concept of the Centaur, introduced by Chess legend Gary Kasparov‚Äìrevolving around the synergy of human and artificial intelligence.
- **Full concept boards** were produced in _Figma_.
- **Logo concepts** were mocked in _Figma_.
- Iterations and **final renders** were produced in _Figma_.

## Graphics

- **High-quality display graphics** were produced for the event.
- Display backgrounds, name cards, and title cards were produced.
- Style matched the event aesthetic I created for the deck & branding.
- **Concepts & final renders** were produced in _Figma_.
- Graphics were **handed off for additional asset creation** to a team in Portugal.

---

### [üß† **Book a meeting to discuss your project. [‚ûî](mailto:alfred.r.duarte@gmail.com)**]{.highlight}

[**alfred.r.duarte@gmail.com**](mailto:alfred.r.duarte@gmail.com "Gmail ‚Äì Alfred R. Duarte")

.

~~~

The above material is owned by the author.

This file was generated with SASHA.

~~~
~~~

llm.txt

Author: Alfred R. Duarte
Domain: https://alfred.ad

~~~

![_Analog Designs Echo Logo Icon, **2022**_](/public/photos/analog-designs/analog-designs-echo-logo.png "Analog Designs Echo Logo Icon, Alfred R. Duarte 2022")

> Design & Product

# Analog Designs

> **2020 ‚Äì April 2025**

> _**Note**: These are one-half of my responsibilities at **Analog Designs**. The companion article on my engineering responsibilities is still being developed._

1. [**Branding**](#branding)
2. [**Design System**](#design-system)
3. [**UI Engine**](#ui-engine)
4. [**Diode**](#diode)
5. [**Website**](#website)

#### Key responsibilities:

- **Founder & CEO**
- **Head of Product**
- **Head of Design**
- **Idea-to-product**
- **Designed the logo & wordmark**
- **Designed & implemented design systems**
- **Designed marketing/branding assets**
- **Developed VST 3 audio plugins**
- **Developed VST 3-compatible UI framework**
- **Developed and shipped OpenGL 2.1 graphics pipeline framework & graphics engine**
- **Implemented custom DSP & Faust DSP pipelines**
- **Collaborated with industry producers & engineers to refine products**
- **Developed brand identity, visual direction, & voice**
- **Created internal tools to accelerate design & engineering workflows**
- **Created design systems; marketing, branding assets; graphic pipeline framework & engine**

#### Tools used:

- [Visual Studio](https://visualstudio.com/)
- [Xcode](https://developer.apple.com/xcode/) (macOS development)
- [VST 3 SDK](https://steinbergmedia.github.io/vst3_dev_portal/pages/index.html)
- [Sketch](https://www.sketch.com/)
- [Adobe Creative Cloud](https://www.adobe.com/creativecloud.html) (marketing assets)
- [Notes (iCloud)](https://www.icloud.com/notes/)
- [Calendar (iCloud)](https://www.icloud.com/calendar/)
- [Reminders (iCloud)](https://www.icloud.com/reminders/)

## Branding

I usually begin with simplicity. Crafting a logo from simple curves/shapes means anyone can draw it‚Äìand it's memorable.

I started with a very simple logo based on the concept of **stereophony** in audio recording.

The placement of your mics affect the amplitude & timing‚Äìthe **phase** of the recorded wave‚Äìwhich produces a **stereo** effect.

![_AB Stereo, **Godbhaal 2013, Public domain, [via Wikimedia Commons](https://commons.wikimedia.org/wiki/File:AB_Stereo.svg "File:AB Stereo.svg ‚Äì Wikimedia Commons")**_](https://upload.wikimedia.org/wikipedia/commons/c/c8/AB_Stereo.svg "AB Stereo, Godbhaal 2013, Public domain, via Wikimedia Commons")

If a bird chirps to your left, the distance traveled by the chirp to your right ear is greater than to your left. This creates a **phase difference**, which you perceive as a small delay on your right ear.

![_Bird Chirp Phase Difference, **2025**_](/public/photos/misc/bird-chirp-phase-difference.png "Bird Chirp Phase Difference, Alfred R. Duarte 2025")

I set up my mics and built out some logo concepts, keeping lines uncomplicated.

![_Analog Designs Logo Concept ‚Ö†, **2022**_](/public/photos/analog-designs/analog-designs-logo-concept-i.png "Analog Designs Concept ‚Ö†, Alfred R. Duarte 2022")

But it felt uninspired & incomplete. I wanted to craft a logo **bold** & **mesmerizing**.

I landed on the concept of the **interval of a sound wave**.

Rather than fluid audio curves, I imagined acoustic pressure waves (moreso amplitude) like sonar.

![_Sonar Principle, **Georg Wiora (Dr. Schorsch) 2008, CC BY-SA 3.0, [via Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Sonar_Principle_EN.svg "File:Sonar Principle EN.svg ‚Äì Wikimedia Commons")**_](https://upload.wikimedia.org/wikipedia/commons/0/07/Sonar_Principle_EN.svg "Sonar Principle, Georg Wiora (Dr. Schorsch) 2008, Wikimedia Commons")

Using these principles, I designed the **logo icon** motif.

![_Analog Designs Stacked Logo Iterations, **2022**_](/public/photos/analog-designs/analog-designs-stacked-logo-iterations.png "Analog Designs Stacked Logo Iterations, Alfred R. Duarte 2022")

- I produced all branding elements, including the **logo icon** & **wordmark**.
- Produced **brand guidelines** for the company.
- Developed **color palette**, **fonts**, & **type presets** for the company.
- Designed logo based around the concept of **sound wave intervals**.
- Full concept boards were produced in _Sketch_.
- Logo concepts were mocked in _Sketch_.
- Iterations and final renders were produced in _Sketch_.

![_Analog Designs Stacked Logo Color, **2022**_](/public/photos/analog-designs/analog-designs-stacked-logo-color.png "Analog Designs Stacked Logo Color, Alfred R. Duarte 2022")

## Design System

I've written a [companion article](/portfolio/design/case-study-ui-styles-i-2022/ "Case Study: UI Styles I, 2022 | Alfred R. Duarte | Portfolio") with a detailed breakdown on the **design system** I developed.

## UI Engine

For more on the **OpenGL 2.1** (not ES2.1‚Äì_the 19 year old 2.1_) **graphics pipeline framework**, **graphics engine**, & **UI framework** I developed, please see [this article](/portfolio/engineering/under-construction/ "UNDER CONSTRUCTION | Alfred R. Duarte | Portfolio").

## Diode

![_Analog Designs Diode Promo ‚Äì Sketch, **2022**_](/public/photos/analog-designs/analog-designs-diode-promo.png "Analog Designs Diode Promo ‚Äì Sketch, Alfred R. Duarte 2022")

- `3` months idea-to-product
- **Designed** using _Sketch_.
- **Developed in custom UI framework**.
- **Implemented custom analog modeling DSP pipelines**.
- **Designed transistor-level circuit components** in _SPICE_.
- **Implemented circuit components** in _Faust_, translated to _custom DSP_.
- **Transistor**; **clipping network**; **biasing**; **RC filters**.
- Implemented **custom DSP pipeline as a VST 3 plugin**.
- **Collaborated with industry producers & engineers** to refine product.

## Website

Part of **Diode**'s marketing pitch is having control over its internal circuit components.

I wanted to play on that using the feeling of _blueprint_ & _wireframe sketches_.

![_Analog Designs Diode Website Mockup ‚Äì Sketch, **2022**_](/public/photos/analog-designs/analog-designs-diode-site.png "Analog Designs Diode Website Mockup ‚Äì Sketch, Alfred R. Duarte 2022")

- `2` weeks idea-to-product.
- Check it out at [analogdesigns.io](https://analogdesigns.io/ "Analog Designs | Modern Analog Modeling").
- **Landing page**, **contact**, & **terms pages**.
- Mockups were produced in _Sketch_.
- Final renders were **translated to and developed in** _React_ & _Tailwind_.
- Custom _react-parallax_ animations.

---

_This project was ultimately paused due to a shortage in personal funds._

.

~~~

The above material is owned by the author.

This file was generated with SASHA.

~~~
~~~

llm.txt

Author: Alfred R. Duarte
Domain: https://alfred.ad

~~~

![_Flying Whale, **2022**_](/public/photos/spaceboy3000/flying-whale.png "Flying Whale, Alfred R. Duarte 2022")

> Case Study ‚Äî Design

# Cartoon Stylized Graphics

> **November 2022**

1. [**General**](#general)
2. [**Curves/Pen Tool**](#curves-pen-tool)
3. [**Colors/Gradients**](#colors-gradients)
4. [**Shading**](#shading)
5. [**Samples**](#samples)

During _Fall 2022_, I was tasked with **mocking up a series of character designs** for a children's sticker subscription box.

The client wanted a **cartoon-stylized look**, with fun, friendly characters. They asked for an "animation" style that "popped".

After completing the project, I wanted to document my learnings & process.

I produced a sprawling `20in` x `200in` poster detailing techniques ranging from **tooling** to **shading**, geared towards replicating the style in vector tools like **Adobe Illustrator**.

I've split the poster into **`4`** sections to make it easier to include in this article.

Techniques discussed are _generalized_ and based on **physical principles** (even though these are cartoons). Most techniques can be easily adapted to other styles.

#### Tools used:

- [Affinity Designer](https://affinity.serif.com/en-us/designer/)

## General

![_General Concepts ‚Äì Cartoon Stylized Graphics Poster, **2022**_](/public/photos/spaceboy3000/cartoon-stylized-graphics-general.png "General Concepts ‚Äì Cartoon Stylized Graphics Poster, Alfred R. Duarte 2022")

## Curves/Pen Tool

![_Curves/Pen Tool Concepts ‚Äì Cartoon Stylized Graphics Poster, **2022**_](/public/photos/spaceboy3000/cartoon-stylized-graphics-curves-pen-tool.png "Curves/Pen Tool Concepts ‚Äì Cartoon Stylized Graphics Poster, Alfred R. Duarte 2022")

## Colors/Gradients

![_Colors/Gradients Concepts ‚Äì Cartoon Stylized Graphics Poster, **2022**_](/public/photos/spaceboy3000/cartoon-stylized-graphics-colors-gradients.png "Colors/Gradients ‚Äì Cartoon Stylized Graphics Poster, Alfred R. Duarte 2022")

## Shading

![_Shading Concepts ‚Äì Cartoon Stylized Graphics Poster, **2022**_](/public/photos/spaceboy3000/cartoon-stylized-graphics-shading.png "Shading Concepts ‚Äì Cartoon Stylized Graphics Poster, Alfred R. Duarte 2022")

## Samples

Below are some discarded samples that never made it to production.

![_D√≠a de los Muertos Holiday Card Sample, **2022**_](/public/photos/spaceboy3000/ddlm-holiday-card.png "D√≠a de los Muertos Holiday Card, Alfred R. Duarte 2022")

![_Girl Singing into Closed Hand Sample, **2022**_](/public/photos/spaceboy3000/sister-22-bday.png "Girl Singing into Closed Hand, Alfred R. Duarte 2022")

![_Turtle Cruising a Lazy River Sample, **2022**_](/public/photos/spaceboy3000/turtle-lazy-river.png "Turtle Cruising a Lazy River, Alfred R. Duarte 2022")

---

### [üé® **Book a meeting to discuss your characters. [‚ûî](mailto:alfred.r.duarte@gmail.com)**]{.highlight}

[**alfred.r.duarte@gmail.com**](mailto:alfred.r.duarte@gmail.com "Gmail ‚Äì Alfred R. Duarte")

.

~~~

The above material is owned by the author.

This file was generated with SASHA.

~~~
~~~

llm.txt

Author: Alfred R. Duarte
Domain: https://alfred.ad

~~~

![_Stromback Venues @ Davos 2025, **2024**_](/public/photos/stromback/stromback-davos.png "Stromback Venues, Davos 2025 Title Card, Alfred R. Duarte 2024")

> Design

# Stromback Venues, World Economic Forum 2025

> **November** - **December 2024**

1. [**Slides**](#slides)
2. [**Graphics**](#graphics)
3. [**Branding**](#branding)

After my initial meetings with the clients, one requirement emerged: _design for the uber-wealthy & heads-of-state_.

**Stromback Venues** provides venue leasing in **Davos, Switzerland** during the [World Economic Forum](https://www.weforum.org/ "The World Economic Forum").

Decks were shown to business & political leaders, including **Elon Musk**, **BlackRock COO**, and **US government officials**.

Decks were used in closing _**`25m`** **in leases**_ for the week of [WEF 2025](https://www.stromback.com/davos "Stromback ‚Äì Davos Experiences").

I was contracted to provide:

- **Initial concepts**
- **Branding**
- **Decks/presentation slides**
- **Lay the groundwork & systems for asset creation**
- **Render high-quality graphics for print/display** (_shown on **CNBC** coverage_)

> _This project extends into a second project with [The Centaurs AI](/portfolio/design/the-centaurs-ai-summit-davos-25-2024/ "The Centaurs AI Summit (Davos '25), 2024")._

Clients came with a strong sense of how they wanted the customer to feel. My role was to interpret their vision‚Äîtranslating vibes into compelling concepts.

Mature asset systems were handed off to a second team in Portugal to facilitate more rapid iterations, as they were in a closer time zone to Switzerland.

This was a first-of-its-kind project for me, as I had never been contracted specifically for _deck slides_.

I determined a simple goal: tell visual stories that excite viewers & incentivize sustained engagement. This without sacrificing the most important aspect of a deck presentation: _readability_.

#### Project length:

**`5 weeks`**

#### Materials produced:

- **`1`** **logo** (multiple iterations); _Figma_
- **`1`** **wordmark** (multiple iterations); _Figma_
- **`1`** **deck**; _Figma_
- **`1`** **deck**; _Google Slides_
- **`2`** **deck themes**; _Figma_
- **`2`** **deck themes**; _Google Slides_
- **`30`** **slides**; _Figma_
- **`30`** **slides**; _Google Slides_
- **`16`** **slide themes**; _Figma_
- **`16`** **slide themes**; _Google Slides_
- **`10`** concept **slide themes**; _Figma_
- **`3`** large-scale **print-ready graphics**; designed in _Figma_, **made print-ready** in _Illustrator_

#### Tools used:

- [Figma](https://www.figma.com/)
- [Google Slides](https://workspace.google.com/products/slides/)
- [Adobe Illustrator](https://www.adobe.com/products/illustrator.html) (Screen-print Preparation)
- [Google Drive](https://workspace.google.com/products/drive/) (Team Collaboration)

## Slides

I was solely responsible for producing the main event deck, presented to prospective customers.

A modern, refined, "_ultra-premium_" look was chosen to capture the emergence of generative AI across global markets.

Certain slides blended a modern look with venue-specific branding, capturing their essence while maintaining overall cohesion.

- Custom **deck slides** were designed in _Figma_.
- Slide content was produced based on an outline document (bullet-points) provided by the clients.
- Clients and I worked together to **develop a story** that I would turn into visual assets.
- Upon approval, the _Figma_ designs were then **fully recreated in Google Slides** for presentation & sharing.
- Further themes for **`2`** **additional decks** were produced in _Figma_, recreated in _Google Slides_, then handed off to the team in Portugal.
- Client strongly preferred matching the aesthetics of the venues for the remaining **`2`** themes‚Äîa **speakeasy theme**, and a **patriotic USA theme**. üá∫üá∏

## Graphics

- **Screen-printed window-graphics** were produced for an exclusive venue attended by VIP US Government officials.
- Large-scale print-ready graphics were designed in _Figma_.
- Designs were drafted & vectorized in _Figma_, then **made print-ready** in _Adobe Illustrator_.
- Graphics were **handed off for screen-printing** near Davos, Switzerland.

## Branding

- Branding elements, including a **logo icon** & **wordmark**, were produced for an _exclusive venue_ attended by VIP US Government officials.
- Drawing on the clients' existing assets and the theme of the event, I drafted designs in the style of **American high-end luxury brands**.
- Full concept boards were produced in _Figma_; research conducted through various **first-party sites** & **in-season winter catalogs**.
- Logo concepts were mocked in _Figma_.
- Iterations and final render were produced in _Figma_.

---

### [üèîÔ∏è **Book a meeting to discuss your project. [‚ûî](mailto:alfred.r.duarte@gmail.com)**]{.highlight}

[**alfred.r.duarte@gmail.com**](mailto:alfred.r.duarte@gmail.com "Gmail ‚Äì Alfred R. Duarte")

.

~~~

The above material is owned by the author.

This file was generated with SASHA.

~~~
~~~

llm.txt

Author: Alfred R. Duarte
Domain: https://alfred.ad

~~~

![_Firecracker Card, **2025**_](/public/photos/agentic-design/firecracker-card.png "Firecracker Card, Alfred R. Duarte 2025")

> Agentic Design & Product

# Firecracker ‚Äî On-Chain Credit Cards

> **May 2025**

1. [**Research & Discovery**](#research-discovery)
2. [**v1: The Problem with "Features First"**](#v1-the-problem-with-features-first)
3. [**v2: Crypto-First Pivot**](#v2-crypto-first-pivot)
4. [**v3: Decentralization as Hero**](#v3-decentralization-as-hero)
5. [**The Winning Formula**](#the-winning-formula)

The workflows **AI agents** offer allow _near instant_ iteration on ideas, market research, and product development.

In this light case study, I explore how **agentic design** could be applied to product. It blends highly emergent technologies with traditional product thinking.

An up‚Äìand‚Äìcoming fintech company is launching a unique crypto product:

### [üß® **Firecracker** ‚Äî on-chain credit cards.]{.highlight}

We'll use **AI agents** to explore the product space, and iterate on the product.

#### Project length:

**`11 hours`**

#### Tools used:

- [Cursor](https://www.cursor.com/)
- [ChatGPT](https://chatgpt.com/) (Product Development)
- [Claude](https://claude.ai/) (Research & Product Development)
- [DeepSeek](https://chat.deepseek.com/) (Research & Discovery)
- [React](https://react.dev/)
- [Tailwind CSS](https://tailwindcss.com/)
- [Hueshift](/portfolio/design/hueshift-2023/ "Hueshift | Alfred R. Duarte | Portfolio") (Color Palettes)

# Research & Discovery

[DeepSeek](https://chat.deepseek.com/ "DeepSeek ‚Äì Into the Unknown") was used to analyze opportunity areas, and guide our path to **product‚Äìmarket fit**.

[Claude](https://claude.ai/ "Claude") was used to substantiate findings and technical feasibility.

Additional research was conducted to understand how **sBTC** unlocks Bitcoin-backed credit without custody risks.

### Competitor gaps

Existing crypto cards (like [Crypto.com](https://crypto.com/us/cards "Crypto.com Visa Card: The only card you need"), [BitPay](https://www.bitpay.com/card "Crypto Debit Card by BitPay | Turn Bitcoin Into Dollars Fast. Get Cash Back.")) rely on custodial models, and fiat transactions with crypto-incentives.

This misses the DeFi-native user, who wants to ***pay in BTC & settle in BTC***.

### User pain points

Nearly **`1`** in **`5`** cryptocurrency owners have had difficulty accessing or withdrawing crypto funds from custodial platforms.[^1]

Custodial platforms force users to lock their crypto in a centralized system, and ask for permission to spend it.

### Technical feasibility

**sBTC**‚Äôs trustless peg allows automated collateralization without centralized issuers (like banks).

You put **BTC** in, and get a loan amount‚Äîno asking, instant approval.

> [**Key insight:**]{.highlight} _Decentralization_ was the unmet need, not just "crypto rewards."

## _Learn a lil' crypto corner_ üí≥

When you use a traditional credit card, the bank is the middleman. They are the custodian of your money‚Äîthey decide when you can use it, and how much you can spend.

Decentralization is about removing the middleman.

[sBTC](https://stacks-network.github.io/stacks/sbtc.html "sBTC: Design of a Trustless Two-way Peg for Bitcoin") enables you to transfer Bitcoin into smart contracts using [**Stacks' Layer 2** (L2) protocol](https://www.stacks.co/learn/introduction "Stacks 101 - Learn about Stacks and why Bitcoin"). You lock your **BTC** into **sBTC**, allowing you to interact with **dApps** that can _instantly_ process your transactions against programmable conditions (like an NFT).

An **on-chain credit card company** could setup a contract to issue lending against your **sBTC**.

1. You lock your **BTC** into **sBTC**.
2. You deposit your **sBTC** into the credit card company's smart contract.
3. The company mints a credit card NFT for you‚Äîno custody, zero permissions.
4. You spend on your collateralized **BTC**.

You can even toss your **sBTC** into a _decentralized_ liquidity pool to earn interest. Other borrowers can borrow against the pool, and you earn interest on the collateral you supplied.

Zero custodial risk, backed by 100% Bitcoin finality.[^2]

# v1: The Problem with "Features First"

### [[**Visit the v1 Site ‚ûî**]{.highlight}](https://fintech-ghost-1.vercel.app/)

### Conversion Killer

**Generic fintech language** ("seamless," "global access") failed to stand out in the crypto space.

**Multi-step signup process** added friction and discouraged users from completing the conversion.

### Missed Opportunity

Value proposition buried below fold under a generic card design.

> [**Key Insight:**]{.highlight} Crypto users need immediate proof of decentralization.

@[110%](https://fintech-ghost-1.vercel.app/)

# v2: Crypto-First Pivot

### [[**Visit the v2 Site ‚ûî**]{.highlight}](https://fintech-ghost-2.vercel.app/)

### What Worked

"**‚Ä¶on-chain credit**" hero text speaks _directly_ to Web3 users.

Added **social proof** ("thousands of early adopters").

More attractive animated card mockup creates desire.

### New Problem

Overwhelming **information density** (6 features + metrics).

> [**Key insight:**]{.highlight} Crypto credit users need to _instantly_ understand the value proposition.

@[110%](https://fintech-ghost-2.vercel.app/)

# v3: Decentralization as Hero

### [[**Visit the Finalized Site ‚ûî**]{.highlight}](https://fintech-ghost-3.vercel.app/)

### Breakthrough Changes

"**Fully decentralized credit card**" above fold instantly communicates _differentiation_.

Card-as-NFT implied through expiration date (**04/28 ‚âÖ Bitcoin halving year**[^3]).

DeFi integration as a **primary feature** (not just "rewards").

### Path to PMF

**Monetize decentralization by packaging it as exclusive next‚Äìgen access.**

> [**Key insight:**]{.highlight} Crypto users value sovereignty above all other features/metrics.

@[110%](https://fintech-ghost-3.vercel.app/)

# The Winning Formula

### [Decentralization Promise (`v2`/`v3`) + Desire (`v2`) + Urgency (`v3`)]{.highlight}

## Why This Works for Crypto Audiences

### **Trust Through Transparency**

[**v3's "secured by you"**]{.highlight} > **`v1's "complete ownership"`**

(_passive_ vs _active_)

### **Scarcity Engineering**

No explicit waitlist number creates **artificial scarcity** (vs v2's "thousands")

### **Technical Credibility**

"Cryptographically secured on-chain" satisfies advanced users without alienating beginners.

Language meets users where they are, highlighting the unique value proposition, without leaning on technical jargon.

## Conclusions

Crypto users prioritize _ownership over convenience_.

A path to **PMF**:

- Monetize decentralization by making it aspirational;
- Make the product experience feel unique and exclusive;
- And make the product feel secure and trustworthy.

In crypto, trust is currency.

***Amplify trust, simplify the experience.***

---

### [üß® **Want to uncover your product's PMF? [‚ûî](mailto:alfred.r.duarte@gmail.com)**]{.highlight}

[**alfred.r.duarte@gmail.com**](mailto:alfred.r.duarte@gmail.com "Gmail ‚Äì Alfred R. Duarte")

[^1]: Cryptocurrency Adoption and Consumer Sentiment Report, [Security.org](https://www.security.org/digital-security/cryptocurrency-annual-consumer-report/ "2025 Cryptocurrency Adoption and Consumer Sentiment Report | Security.org")

[^2]: Bitcoin has 100% finality on the Stacks L2 protocol thanks to the Nakamoto upgrade, [Stacks.org](https://stacks.org/nakamoto-is-here "Finally, Finality: Nakamoto Upgrade Sets the Stage sBTC, Bitcoin for Builders").

[^3]: The fifth Bitcoin halving is anticipated around April 2028, [Kraken.com](https://www.kraken.com/learn/bitcoin-halving-history#article-block-9943a4d1f561 "What is Bitcoin Halving? | Blockchain.com").


~~~

The above material is owned by the author.

This file was generated with SASHA.

~~~
~~~

llm.txt

Author: Alfred R. Duarte
Domain: https://alfred.ad

~~~

![_`Sasha` Article Transformation, **2025**_](/public/photos/sasha/sasha-article-transformation.png "Sasha Article Transformation, Alfred R. Duarte 2025")

> Engineering

# Static Site Generator

> **April 2025**

### _GitHub_: **[`trainingmode/portfolio`](https://github.com/trainingmode/portfolio "trainingmode/portfolio: Micro static site generator.")**

1. [**Overview**](#overview)
2. [**Workflow**](#workflow)
3. [**Writing Articles**](#writing-articles)
4. [**Template System**](#template-system)
5. [**Portfolio Site**](#portfolio-site)
6. [**Benchmarks & Metrics**](#benchmarks-metrics)
7. [**Improvement Targets**](#improvement-targets)

### [[**‚Üí *This site loads in under 0.8s on mobile, 0.2s on desktop***](https://pagespeed.web.dev/analysis/https-alfred-ad/6hw2k04xoa?form_factor=mobile "alfred.ad ‚Äî Mobile Device Metrics ‚Äî PageSpeed Insights")]{.highlight} (PageSpeed Insights)

My portfolio site is built with a custom [static site generator](https://developer.mozilla.org/en-US/docs/Glossary/SSG "Static site generator (SSG) - MDN Web Docs Glossary: Definitions of Web-related terms | MDN").

Markdown **articles** & folder **directories** are rendered into **HTML** templates.

I needed a simple system to write articles and generate a site that was effortless to maintain. My core focus was writing articles and designing a site that was **100%** accessible.

What I've learned from previous projects is to reduce or avoid complexity. I would have just written pure HTML, but that makes for a horrible experience writing neatly‚Äìformatted articles.

There is only **_`1`_** line of inline JavaScript on this site. It's on the email button CTA, needed to copy my email to your clipboard and close the context menu:

```javascript
onclick = `navigator.clipboard.writeText("alfred.r.duarte@gmail.com");this.blur();`;
```

Everything else is just **vanilla HTML** & **Tailwind CSS**.

~[autoplay muted loop playsinline width="1400" class="rounded-lg"](/public/media/alfred-portfolio-lighthouse-metrics.mp4 "video/mp4")

My [Lighthouse metrics](https://pagespeed.web.dev/analysis/https-alfred-ad/6hw2k04xoa?form_factor=mobile "alfred.ad ‚Äî Mobile Metrics ‚Äî PageSpeed Insights") speak for themselves.

I didn't even know it had fireworks.

#### Tools used:

- [Cursor](https://www.cursor.com/)
- [Pandoc](https://pandoc.org/)
- [Bash 5](https://www.gnu.org/software/bash/manual/bash.html)
- [Vercel serve](https://github.com/vercel/serve) (dev server)
- [Chokidar](https://github.com/paulmillr/chokidar)
- [Tailwind CSS](https://tailwindcss.com/)
- [HTML](https://html.spec.whatwg.org/multipage/)
- [Sketch](https://www.sketch.com/) (diagrams)

# Overview

Built on the **`Directory`** ‚Üí **`Article`** folder structure concept. Similar to other Static Site Generators like [Jekyll](https://jekyllrb.com/ "Jekyll ‚Ä¢ Simple, blog-aware, static sites | Transform your plain text into static websites and blogs") or [Gatsby](https://www.gatsbyjs.com/ "The Best React-Based Framework | Gatsby").

It's essentially a **Markdown** converter with a simple template system. Generated sites are just HTML files, organized in the folder structure you provide in the input directory.

Internally, **articles** are converted using **Pandoc**. [Pandoc converts all files to HTML by default](https://pandoc.org/MANUAL.html#specifying-formats "Specifying formats ‚Äì Pandoc ‚Äì Pandoc User‚Äôs Guide"). While you could write articles in any markup format that **Pandoc** supports, only **Markdown** is supported.

A set of internal **plugins** preprocess special **Markdown** syntax, like **video** and **embedded iFrames**.

```md
# Video Component

‚àº[<video> Attributes](link "type")

# Example

‚àº[loop controls playsinline width="320" class="rounded-lg ring-(--color-primary) ring-0 ring-offset-1 hover:ring-4 active:ring-2 transition-shadow"](/public/media/alfred-portfolio-lighthouse-metrics.mp4 "video/mp4")
```

**_Output:_**

~[loop controls playsinline width="320" class="rounded-lg ring-(--color-primary) ring-0 ring-offset-1 hover:ring-4 active:ring-2 transition-shadow"](/public/media/alfred-portfolio-lighthouse-metrics.mp4 "video/mp4")

Both **article** files & **directory** folders are rendered as pages in your site. **Directory** pages display **article** listings and other **directory** subfolders.

Complete documentation can be found in the [project **`README`**](https://github.com/trainingmode/portfolio?tab=readme-ov-file#sasha--static-site-generator "trainingmode/portfolio: Micro static site generator.").

# Workflow

The **static site generator** is a set of bash scripts.

The **CLI** is used to watch the current project directory for changes and preview your site.

Your site is automatically rebuilt when the **CLI** observes any changes. You can specify an `.ssgignore` file to define excluded file/folder patterns.

A **`ssg.config` Configuration** file is created for you when you first run the **CLI**. It contains a few settings, like your domain for [canonical](https://developers.google.com/search/docs/crawling-indexing/canonicalization "What is URL Canonicalization | Google Search Central | Documentation | Google for Developers") & [Open Graph](https://ogp.me/#metadata "Basic Metadata ‚Äî The Open Graph protocol") URLs. None of the settings are required.

A folder of **templates** is used to render your folder of **articles** & **directories** into **HTML** pages. The generated pages are saved into the output folder. The structure of the output folder will mirror the input folder.

## CLI

The **CLI** is the main entrypoint for the SSG.

It watches the current directory and serves your site for previewing.

```sh
./ssg.sh ssg.config "articles" "build"
```

## Builder

You can run the **Builder** manually to build your site.

```sh
./build.sh ssg.config "articles" "build"
```

The [**CLI**](#cli) can be used to watch your project directory and automatically rebuild your site.

## Development Server

The **Development Server** is a simple [serve](https://github.com/vercel/serve "vercel/serve ‚Äî GitHub")‚Äìbased HTTP server for previewing your site.

```sh
./server.sh 3000
```

The server isn't **WebSockets**‚Äìbased, so you'll need to refresh your browser to see changes.

The [**CLI**](#cli) will automatically launch the server for you.

# Writing Articles

**Articles** are formatted in [**Markdown**](https://commonmark.org/ "CommonMark").

**Article heading images** are extracted as the **thumbnail**. The **thumbnail** is displayed in **directory** pages and for sharing on social media. The first image in the article is used.

**Article titles** are extracted from the filename. Filenames are slugified for SEO‚Äìfriendly URLs.

**Article descriptions** are extracted as the first paragraph of the article.

You can define an **article category** by adding a **`>` Blockquote** before the first heading.

```md
> Case Study
# Light & Shadows
```

## Article Components

**Article components** allow you to transform content using special **Markdown** syntax.

A handful are available. Currently, they all extend the **`[]()` link`** syntax.

For example, add `+` to the beginning of a link to turn it into a **download link**.

```md
Ôºã[Download Sketch Diagram](https://drive.google.com/uc?export=download&id=1p-IP3XXRX8CAVHfLlhyUw3MDdahVhUTv "Sasha Layout Assembly Diagram (Sketch), Alfred R. Duarte 2025.zip")
```

**_Output:_**

+[Download Sketch Diagram](https://drive.google.com/uc?export=download&id=1p-IP3XXRX8CAVHfLlhyUw3MDdahVhUTv "Sasha Layout Assembly Diagram (Sketch), Alfred R. Duarte 2025.zip")

See the [project **`README`**](https://github.com/trainingmode/portfolio?tab=readme-ov-file#article-components "trainingmode/portfolio: Micro static site generator.") for complete documentation.

## Article Listing Symbols

Special symbols are used to designate the **article listing** type.

- **`*` Pinned**
- **`~` Hidden**
- **`_` Not Rendered**

For example, `~ Hueshift, 2023.md` will render as a page, but will not be listed in any **directory** page.

# Template System

The **template system** assembles template fragments into a final layout.

It uses **`.frag.html` fragment HTML** files for templates.

There are no restrictions, and there are plenty of **`{{ }}` Replacement Tags** for injecting content parsed from your articles.

You can target **templates** to specific **articles** by mirroring the structure of your articles folder.

## Layouts

Layout templates are used to render both **article** & **directory** pages.

Layouts follow a hierarchal order to building a final **HTML** page.

![_`Sasha` Layout Assembly Diagram, **2025**_](/public/photos/sasha/sasha-layout-assembly.png "Sasha Layout Assembly Diagram, Alfred R. Duarte 2025")

**Articles** are first converted to **HTML** using **Pandoc**.

Through a series of **`{{ }}` Replacement Tags**, the **template system** assembles fragments and injects them into the **`layout.frag.html` Layout Template** file.

The final output is a self‚Äìcontained **HTML** page.

## Replacement Tags

The **template system** uses **`{{ }}` Replacement Tags** to inject content into **template fragments**.

All tags are optional, and some tags can be used site‚Äìwide.

```html
<!-- Layout Template -->
 
<!DOCTYPE html>
<html lang="en">
{{HEAD}}
{{BODY}}
{{FOOTER}}
</html>
```

The [project **`README`**](https://github.com/trainingmode/portfolio?tab=readme-ov-file#templates "trainingmode/portfolio: Micro static site generator.") contains complete documentation for the **template system**.

# Portfolio Site

For my portfolio site itself, I mixed **pure HTML** with [**Tailwind CSS**](https://tailwindcss.com/ "Tailwind CSS ‚Äî Rapidly build modern websites without ever leaving your HTML.") to design templates.

My portfolio site is deployed on [GitHub Pages](https://pages.github.com/ "GitHub Pages | Websites for you and your projects, hosted directly from your GitHub repository. Just edit, push, and your changes are live.").

Writing articles, designing templates, and building this SSG took blended about 3 weeks.

## Designing with Tailwind

During development, the [Tailwind Play CDN](https://tailwindcss.com/docs/installation/play-cdn "Play CDN ‚Äì Tailwind CSS") was used. Performance is fairly slow loading **Tailwind** from the CDN each time a page loads.

For production, the [Tailwind CLI](https://tailwindcss.com/docs/installation/tailwind-cli "Tailwind CLI ‚Äì Tailwind CSS") was used. Since **Node.js** is not used in this project, the CLI was installed via the [standalone method recommended by Tailwind](https://tailwindcss.com/blog/standalone-cli "Standalone CLI: Use Tailwind CSS without Node.js ‚Äì Tailwind CSS").

```bash
curl -sLO https://github.com/tailwindlabs/tailwindcss/releases/latest/download/tailwindcss-macos-arm64 && chmod +x tailwindcss-macos-arm64 && mv tailwindcss-macos-arm64 tailwindcss
```

It downloads as a single `tailwindcss` binary.

```bash
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ tailwindcss
```

After installing the executable, I continued the regular [Tailwind CLI installation](https://tailwindcss.com/docs/installation/tailwind-cli "Tailwind CLI ‚Äì Tailwind CSS").

First import **Tailwind** into the **main stylesheet**.

**`styles.css`**

```css
@import "tailwindcss";
```

Then replace the CDN with the **stylesheet generated by Tailwind**.

**`index.html`**

```diff
-  <script src="https://cdn.tailwindcss.com"></script>
+  <link rel="stylesheet" href="/public/tailwind.css" />
```

Finally, compile **Tailwind**.

The **`-m` minifier** reduces the output size.

The **`-w` watcher** observes changes in your project and automatically rebuilds the Tailwind stylesheet.

```bash
./tailwindcss -i "./public/styles.css" -o "./public/tailwind.css" -m -w
```

In total this setup took about 5‚Äì10 minutes.

This was my first time using **Tailwind** with vanilla HTML and I really enjoyed it. Using it with my **template system** felt like a natural extension from other technologies like [React](https://react.dev/ "React").

# Benchmarks & Metrics

***Every single page on my site achieves `100` Best Practices & SEO scores.***

Certain pages on my site achieve perfect **`100`** scores on [PageSpeed Insights](https://pagespeed.web.dev/analysis/https-alfred-ad/6hw2k04xoa?form_factor=mobile "alfred.ad ‚Äî Mobile Device Metrics ‚Äî PageSpeed Insights") (Lighthouse).

![_Alfred Portfolio Home Page Lighthouse Metrics, **2025**_](/public/photos/sasha/portfolio-home-lighthouse-metrics.png "Alfred Portfolio Home Page Lighthouse Metrics, Alfred R. Duarte 2025")

***There are zero errors site-wide.***

![_Alfred Portfolio Clean Console Logs, **2025**_](/public/photos/sasha/portfolio-clean-console-logs.png "Alfred Portfolio Clean Console Logs, Alfred R. Duarte 2025")

## Lighthouse Metrics

Below are a sampling of [Lighthouse](https://developer.chrome.com/docs/lighthouse "Lighthouse | Chrome for Developers") reports (via **PageSpeed Insights**) for some pages.

Metrics are based on **mobile devices**.

|   | **FCP** | **LCP** | **Speed Index** | **Performance** | **Accessibility** | **Report** |
| --- | --- | --- | --- | --- | --- | --- |
| [`/`](/ "Alfred R. Duarte \| Portfolio Home") | **`0.8s`** | **`0.8s`** | **`0.8s`** | ‚úÖ **`100`** | ‚úÖ **`100`** | [PageSpeed](https://pagespeed.web.dev/analysis/https-alfred-ad/q7m2zpfdhr?form_factor=mobile "alfred.ad ‚Äî Mobile Device Metrics ‚Äî PageSpeed Insights") |
| [`/design`](/portfolio/design/ "Design \| Alfred R. Duarte \| Portfolio") | **`0.9s`** | **`8.7s`** | **`3.5s`** | üü° **`74`** | ‚úÖ **`100`** | [PageSpeed](https://pagespeed.web.dev/analysis/https-alfred-ad-portfolio-design/unm40zyykf?form_factor=mobile "alfred.ad/portfolio/design ‚Äî Mobile Device Metrics ‚Äî PageSpeed Insights") |
| [`/design/emojis`](/portfolio/design/color-emoji-ios-6-2022/ "Color Emoji (iOS 6), 2022 \| Alfred R. Duarte \| Portfolio") | **`0.9s`** | **`15.5s`** | **`3.5s`** | üü° **`74`** | üü° **`86`** | [PageSpeed](https://pagespeed.web.dev/analysis/https-alfred-ad-portfolio-design-color-emoji-ios-6-2022/m1nut8tn2d?form_factor=mobile "alfred.ad/portfolio/design/color-emoji-ios-6-2022 ‚Äî Mobile Device Metrics ‚Äî PageSpeed Insights") |

**Performance** drops when a page includes a lot of media.

**Accessibility** drops a bit on **article** pages due to the way some headings are used.

Personally, I think semantically skipping an `<h2>` to create a subheading `<h3>` is perfectly reasonable. It also reads in plain English‚Äî_the subheading before the following section_.

```md
# Title

### Subheading ‚Üê[ Triggers Accessibility Error ]

## Section
```

**Deployed sites** ship with only what they need. A generated **article** page is only a few dozen kilobytes in size. Media used in an **article** will increase its page size.

My [Emoji Case Study](/portfolio/design/color-emoji-ios-6-2022/ "Color Emoji (iOS 6), 2022 | Alfred R. Duarte | Portfolio") page is **`13.5MB`** including images and transfers in **`246ms`**.

![_Alfred Portfolio Network Load, **2025**_](/public/photos/sasha/portfolio-network-load.png "Alfred Portfolio Network Load, Alfred R. Duarte 2025")

As you can see, images are the largest bottleneck. Currently there is no image optimization (lazy loading, serving smaller images for mobile, etc). This is a clear target for future optimization.

## Builder Benchmarks

An article with **`2069`** words (my [**Dataing**](/portfolio/design/dataing-2023-2025/ "Dataing, 2023-2025 | Alfred R. Duarte | Portfolio") article) renders in around **`64ms`**.

![_`Sasha` Terminal Output, **2025**_](/public/photos/sasha/sasha-terminal-output.png "Sasha Terminal Output, Alfred R. Duarte 2025")

My entire portfolio site with **`10`** articles renders in just under **`3s`**. It's lengthy but doesn't feel too bad when writing articles.

This could be improved by only rebuilding changed articles. However, it would require hacking the **chokidar-cli** output to determine which files changed.

It would make more sense to translate the **CLI** to **Node.js** and use **WebSockets** to trigger rebuilds. For this project, this was an acceptable compromise given I was focused primarily on writing articles.

# Improvement Targets

There are a handful of targets for improvement that exceeded the initial scope of this project.

I was mainly focused on writing articles for my portfolio and didn't want to add complexity.

- **Image Optimization**  
  _Impact_: üî¥ **_Critical_**  
  Images are served at their original size. This could be improved with build-time optimization to resize & compress images. This would significantly reduce page size and thusly data usage for mobile users.

- **Node.js Translation**  
  _Impact_: üü° _Low_  
  The **CLI** is a shell script. Rewriting the **CLI** in **Node.js** would improve developer experience, and allow for extended features like WebSockets & plugins.

- **Targeted Rebuilds**  
  _Impact_: üü° _Low_  
  Every change currently triggers a full site rebuild. **Hashing files** & building a **dependency graph** would allow for granular rebuilding of only files that changed. This would significantly reduce build times.

- **WebSockets**  
  _Impact_: üîµ _Feature_  
  Browsers must be manually refreshed to see changes after rebuilds. WebSocket-based **hot reloading** would enable immediate visual feedback while writing articles. This would greatly improve the experience for content creators.

In all, I'm satisfied with performance results and **CLI** UX given the scope.

Removing complexity from this project taught me a lot about focusing on the core experience.

Performant & accessible design can look beautiful, too.

---

### [üßëüèΩ‚Äçüíª **Book a meeting to discuss your project. [‚Üí](mailto:alfred.r.duarte@gmail.com)**]{.highlight}

[**alfred.r.duarte@gmail.com**](mailto:alfred.r.duarte@gmail.com "Gmail ‚Äì Alfred R. Duarte")


~~~

The above material is owned by the author.

This file was generated with SASHA.

~~~
